# Research2Presentation: Codebase Guide

This document provides a human-readable explanation of the project structure and the code workflow. It is designed to help you understand "what lives where" and "how it works" at a glance.

---

## ðŸ“‚ Folder Structure Explanation

### 1. Root Directory (`./`)
*   **`paper2slides.py`**: **The Orchestrator**. This is the main script you run. It doesn't do the heavy lifting itself; instead, it calls other scripts to generate slides, then generate narration, and finally combine them.
*   **`paper2ppt_cli.py`**: **The Slide Builder**. This script is responsible for reading the PDF, understanding its sections (Intro, Method, etc.), and creating the visual PowerPoint slides with bullet points and images.
*   **`requirements.txt`**: Lists all the Python libraries required to run the project.

### 2. Narration Module (`ppt_narration_project/`)
*   **Purpose**: Handles everything related to speaking. It looks at the slides generated by the previous step and adds a "voice".
*   **`main.py`**: The sub-manager for this specific module.
*   **`narration_generator.py`**: Uses AI (Qwen) to write a script for what a speaker *should* say for each slide.
*   **`tts_generator.py`**: Converts the written script into audio files using Edge-TTS (Text-to-Speech).
*   **`ppt_audio_embedder.py`**: Takes the audio files and "sticks" them inside the PowerPoint file so they play automatically.

### 3. Core Logic (`paper2ppt_core/`)
*   **Purpose**: Helper functions that do the specific, messy work of processing files.
*   **`io.py`**: Handles Input/Output. Specifically, reading PDF files and extracting text/images.
*   **`sections.py`**: "Smart" logic that reads the raw text and figures out where the "Introduction" ends and the "Method" begins.
*   **`pptx_builder.py`**: The actual code that draws boxes, text, and titles onto a PowerPoint slide.

### 4. Models (`models/`)
*   **Purpose**: Contains the interface for the AI Brain.
*   **Model Used**: **Qwen 2.5 7B Instruct** (`Qwen/Qwen2.5-7B-Instruct`)
*   **Where it is used**:
    *   **Summarization**: Used in `paper2ppt_cli.py` to generate concise, high-quality bullet points from raw academic text.
    *   **Narration**: Used in `ppt_narration_project/narration_generator.py` to create natural-sounding speaker scripts for each slide.
*   **Why this model is better than others**:
    *   **Top-Tier Performance**: Qwen 2.5 7B is currently one of the strongest open-source models in its size class, often outperforming larger models in reasoning and instruction following.
    *   **Efficiency**: It is lightweight enough to run locally on consumer hardware (using 8-bit quantization), removing the need for expensive cloud APIs.
    *   **Privacy**: Since it runs entirely on your machine, no sensitive research paper data is sent to external servers.
    *   **Structure Adherence**: It excels at following strict formatting constraints (e.g., "no conversational filler", "exact number of bullets"), which is crucial for automated slide generation.
*   **`qwen_llm.py`**: The bridge between our code and the Qwen AI model. It sends text prompts and gets answers (summaries/narrations) back.

### 5. Scripts (`scripts/`)
*   **Purpose**: A dumping ground for utility scripts, tests, and small tools that aren't part of the main pipeline but are useful for debugging or specific small tasks.

### 6. Archive (`archive/`)
*   **Purpose**: Old or unused code. Kept just in case we need to look at how things used to work.

---

## âš™ï¸ Workflow: How the Code Specifics Work

Here is the step-by-step logic of what happens when you run `python3 paper2slides.py aiawn.pdf`:

### Step 1: Input & Extraction
*   **Code**: `paper2ppt_cli.py` -> `paper2ppt_core/io.py`
*   **Action**: The script opens your PDF. It converts the PDF into raw text and also saves every image it finds into a temporary folder (`paper2ppt_figs`).

### Step 2: Intelligent Sectioning
*   **Code**: `paper2ppt_cli.py` -> `paper2ppt_core/sections.py`
*   **Action**: The script scans the raw text for keywords like "Abstract", "Introduction", "Method", "Experiments". It splits the long text into these logical chunks.

### Step 3: Content Filtering & Bulleting
*   **Code**: `paper2ppt_cli.py` (Functions: `extract_sentences`, `rewrite_bullet`)
*   **Action**:
    *   It looks at each section (e.g., Intro).
    *   It extracts sentences that look like valid information (ignoring references like `[12]`).
    *   It filters for "high signal" sentences (those containing words like *proposed*, *method*, *achieves*).
    *   It converts these sentences into clean bullet points.
    *   **Logic**: If a section has too many bullets (e.g., 20 bullets for "Results"), it automatically splits them into "Results" and "Results (continued)" slides.

### Step 4: Slide Creation
*   **Code**: `paper2ppt_core/pptx_builder.py`
*   **Action**: It creates a `.pptx` file. For each section, it makes a new slide, puts the title at the top, pastes the bullet points, and inserts extracted images if they belong to that section (usually Method/Results).
*   **Result**: You get `output.pptx`.

### Step 5: Narration Generation (AI)
*   **Code**: `ppt_narration_project/narration_generator.py` -> `models/qwen_llm.py`
*   **Action**: The script reads the *slides* it just made. For each slide, it asks the AI (Qwen): *"Explain this slide to an audience."* The AI writes a paragraph of text.

### Step 6: Audio Synthesis (TTS)
*   **Code**: `ppt_narration_project/tts_generator.py`
*   **Action**: It takes the AI-written paragraph and sends it to Edge-TTS. This generates a `.mp3` or `.wav` file of a human-sounding voice reading the text.

### Step 7: Final Assembly
*   **Code**: `ppt_narration_project/ppt_audio_embedder.py`
*   **Action**: It opens the `output.pptx` again. It inserts the audio file onto the correct slide and sets it to "Play in Background". It saves the final result as `<paper_name>_summary_with_narration.pptx`.
